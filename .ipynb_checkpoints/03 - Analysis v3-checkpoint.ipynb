{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fce0a00c",
   "metadata": {},
   "source": [
    "# LDA Topic Modeling for Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691c20d7",
   "metadata": {},
   "source": [
    "## Andy Karr "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a5dd9",
   "metadata": {},
   "source": [
    "## 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519ddfc",
   "metadata": {},
   "source": [
    "This report investigates 12,415 reviews taken from 2017-2021 and segments them into topics using LDA Topic Modeling. \n",
    "\n",
    "The purpose of this investigation is to find 3 to 7 topics (the best number of topics will be statistically investigated), to highlight what those topics are and to segment new data into these topics.\n",
    "\n",
    "It was found from using coherence score analysis that 7 topics gives the highest coherence score and therefore it is most optimal to use 7 topics.\n",
    "\n",
    "Some stopwords were removed from the cleaning of the text to allow for terms such as \"not good\" - normally words like \"not\" are removed from texts as this is a stop word but we want to retain the sentiment of \"not good\" being negative.\n",
    "\n",
    "The report is split into the following sections.\n",
    "\n",
    "1. Preparation of the data.\n",
    "2. Building the model and exploring the created topics.\n",
    "3. Visualisation of the model.\n",
    "4. Using new reviews and assigning them to our created topics. I used 2 mock reviews for this as a demonstration and left instructions how to assign topics to new reviews further below in section 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff02d2a",
   "metadata": {},
   "source": [
    "## 1. Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17dd3b",
   "metadata": {},
   "source": [
    "### 1.1 Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "7a24c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2f08b9",
   "metadata": {},
   "source": [
    "### 1.2 Glance at the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "85b1a8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback_created_at</th>\n",
       "      <th>final_msg_join</th>\n",
       "      <th>feedback_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-10 08:00:18</td>\n",
       "      <td>top</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-10 08:51:40</td>\n",
       "      <td>blinker defect break delay</td>\n",
       "      <td>blinker defect, break work delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-10 08:43:30</td>\n",
       "      <td>app really well</td>\n",
       "      <td>App did not work really well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-10 09:51:10</td>\n",
       "      <td>ending ride first attempt start app try</td>\n",
       "      <td>Ending ride didn’t work at first attempt. I had to restart the app and try again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-10 10:04:59</td>\n",
       "      <td>battery keep change level dramatically</td>\n",
       "      <td>Battery kept changing its level dramatically.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feedback_created_at                           final_msg_join  \\\n",
       "0  2017-11-10 08:00:18                                      top   \n",
       "1  2017-11-10 08:51:40               blinker defect break delay   \n",
       "2  2017-11-10 08:43:30                          app really well   \n",
       "3  2017-11-10 09:51:10  ending ride first attempt start app try   \n",
       "4  2017-11-10 10:04:59   battery keep change level dramatically   \n",
       "\n",
       "                                                                   feedback_message  \n",
       "0                                                                               Top  \n",
       "1                                                blinker defect, break work delayed  \n",
       "2                                                     App did not work really well   \n",
       "3  Ending ride didn’t work at first attempt. I had to restart the app and try again  \n",
       "4                                    Battery kept changing its level dramatically.   "
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/final_df.csv')\n",
    "#print(df.to_string())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f36f7bb",
   "metadata": {},
   "source": [
    "### 1.3 Frequency of reviews for each year¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "6ef29a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T430\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='year'>"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Date']= pd.to_datetime(df['feedback_created_at'])\n",
    "df['final_msg_join'] = df['final_msg_join'].astype(str)\n",
    "df['year'] = pd.DatetimeIndex(df['Date']).year\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "\n",
    "\n",
    "tfidf_text = TfidfVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)\n",
    "vectors_text = tfidf_text.fit_transform(df['final_msg_join'])\n",
    "vectors_text.shape\n",
    "\n",
    "%matplotlib inline\n",
    "df.groupby('year').agg({'final_msg_join': 'count'}).plot.bar(figsize=(15,5),width=0.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def6dea3",
   "metadata": {},
   "source": [
    "### 1.4 Data prep\n",
    "\n",
    "The data is prepared by \n",
    "1. Taking out stopwords.\n",
    "2. Tokenisation (splitting the reviews into individual words).\n",
    "3. Taking bigrams and trigrams.\n",
    "\n",
    "Some notes to make here are for stop words, some negative words such as \"not\" are normally taken out but for this analysis I believe it's important. For example, there is a review that said \"not good\". Normally, the stop word would take out the \"not\" part and leave out the \"good\". This means that the message would be interpreted as positive but it's actually not. For that reason I used a manual list of stop words and generally left in words like \"not\" or \"couldn't\" as I believe this is important for the analysis.\n",
    "\n",
    "Equally, I included bigrams and trigrams. These are simple things. The default behaviour of this modeling is to use single words and use them for the analysis, for example if a review said \"the bike is not good\", each word, \"the\", \"bike\", \"is\", \"not\", \"good\" are used individually in the analysis (actually \"the\" and \"is\" are stop words and are removed). I have used bigrams which means we group 2 words together, therefore \"not good\" will be taken together as a word in the analysis. This captures the sentiment of it being bad. Trigrams work in a similar way but with 3 words, for example \"not working well\" will be grouped together and used in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0710ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m spacy download en\n",
    "import re, numpy as np, pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import  simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = ['i',\n",
    " 'me',\n",
    " 'my',\n",
    " 'myself',\n",
    " 'we',\n",
    " 'our',\n",
    " 'ours',\n",
    " 'ourselves',\n",
    " 'you',\n",
    " \"you're\",\n",
    " \"you've\",\n",
    " \"you'll\",\n",
    " \"you'd\",\n",
    " 'your',\n",
    " 'yours',\n",
    " 'yourself',\n",
    " 'yourselves',\n",
    " 'he',\n",
    " 'him',\n",
    " 'his',\n",
    " 'himself',\n",
    " 'she',\n",
    " \"she's\",\n",
    " 'her',\n",
    " 'hers',\n",
    " 'herself',\n",
    " 'it',\n",
    " \"it's\",\n",
    " 'its',\n",
    " 'itself',\n",
    " 'they',\n",
    " 'them',\n",
    " 'their',\n",
    " 'theirs',\n",
    " 'themselves',\n",
    " 'what',\n",
    " 'which',\n",
    " 'who',\n",
    " 'whom',\n",
    " 'this',\n",
    " 'that',\n",
    " \"that'll\",\n",
    " 'these',\n",
    " 'those',\n",
    " 'am',\n",
    " 'is',\n",
    " 'are',\n",
    " 'was',\n",
    " 'were',\n",
    " 'be',\n",
    " 'been',\n",
    " 'being',\n",
    " 'have',\n",
    " 'has',\n",
    " 'had',\n",
    " 'do',\n",
    " 'does',\n",
    " 'did',\n",
    " 'doing',\n",
    " 'a',\n",
    " 'an',\n",
    " 'the',\n",
    " 'and',\n",
    " 'but',\n",
    " 'if',\n",
    " 'or',\n",
    " 'because',\n",
    " 'as',\n",
    " 'until',\n",
    " 'while',\n",
    " 'of',\n",
    " 'at',\n",
    " 'by',\n",
    " 'for',\n",
    " 'with',\n",
    " 'about',\n",
    " 'between',\n",
    " 'into',\n",
    " 'through',\n",
    " 'during',\n",
    " 'before',\n",
    " 'after',\n",
    " 'above',\n",
    " 'below',\n",
    " 'to',\n",
    " 'from',\n",
    " 'out',\n",
    " 'under',\n",
    " 'then',\n",
    " 'once',\n",
    " 'here',\n",
    " 'there',\n",
    " 'when',\n",
    " 'where',\n",
    " 'why',\n",
    " 'how',\n",
    " 'both',\n",
    " 'each',\n",
    " 'few',\n",
    " 'other',\n",
    " 'some',\n",
    " 'only',\n",
    " 'own',\n",
    " 'same',\n",
    " 'so',\n",
    " 'than',\n",
    " 'too',\n",
    " 'very',\n",
    " 's',\n",
    " 't',\n",
    " 'can',\n",
    " 'will',\n",
    " 'just',\n",
    " 'don',\n",
    " 'should',\n",
    " \"should've\",\n",
    " 'now',\n",
    " 'd',\n",
    " 'll',\n",
    " 'm',\n",
    " 'o',\n",
    " 're',\n",
    " 've',\n",
    " 'y',\n",
    " 'isn',\n",
    " \"isn't\",\n",
    " 'ma',\n",
    " 'mightn',\n",
    " \"mightn't\",\n",
    " 'mustn',\n",
    " \"mustn't\",\n",
    " 'needn',\n",
    " \"needn't\",\n",
    " 'shan',\n",
    " \"shan't\",]\n",
    "\n",
    "\n",
    "#animals.remove('rabbit')\n",
    "\n",
    "\n",
    "#stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come'])\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent)  \n",
    "\n",
    "# Convert to list\n",
    "data = df.feedback_message.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "#print(data_words[:3])\n",
    "\n",
    "\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=10) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=5)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# !python3 -m spacy download en  # run in terminal once\n",
    "def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc])# if token.pos_ in allowed_postags])\n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
    "    return texts_out\n",
    "\n",
    "data_ready = process_words(data_words)  # processed Text Data!\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ac158d",
   "metadata": {},
   "source": [
    "## 2. LDA Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a7471c",
   "metadata": {},
   "source": [
    "### 2.1 Run the model and look at the words that contribute most to each topic\n",
    "\n",
    "The below output shows for each topic the words that contribute the most to that topic, for example \"0\" shows \"not\" contributing most to topic 0, \"break\" contributing most to topic 1, and so on. This will be presented clearer later on in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=7, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=10,\n",
    "                                           passes=10,\n",
    "                                           alpha='symmetric',\n",
    "                                           iterations=100,\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120062e6",
   "metadata": {},
   "source": [
    "### 2.2a Coherence score check\n",
    "The following code chunk gives us the coherence score for 7 topics. We get a score of 0.39, which tells us if 7 topics is a good number of topics. This is a relatively low score. This can be explained by the fact there are many reviews with low amount of words, sometimes single words such as \"top\". With more words in each review, this score would increase. Given this fact, a coherence of 0.39 is acceptable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f323cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "lda_gensim_para_coherence = CoherenceModel(model=lda_model,\n",
    "    texts=data_ready, dictionary=id2word, coherence='c_v')\n",
    "lda_gensim_para_coherence_score = lda_gensim_para_coherence.get_coherence()\n",
    "print(lda_gensim_para_coherence_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e4bbf4",
   "metadata": {},
   "source": [
    "### 2.2b Check what is the best number of topics\n",
    "\n",
    "The following code gets the coherence score of each lda model run using topics in the range 3 to 7 to find which is the most optimal amount of topics. A high coherence score means a good number of topics. In this final report the code isn't run because it takes a long time and therefore I commented it out. \n",
    "\n",
    "However, I did run this code previously and found 7 was the best number of topics. When I ran it the pre-processing of the data wasn't as good so we see a lower score than above for 7 topics, but 7 topics would still come out as the winner after these new pre-processing applications.\n",
    "\n",
    "The image of this plot follows. It shows 7 topics has the highest coherence score and therefore we use 7 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"coherence.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b03602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from gensim.models.ldamulticore import LdaMulticore\n",
    "# lda_para_model_n = []\n",
    "# for n in range(3, 8):\n",
    "#     lda_model_c = LdaMulticore(corpus=corpus, id2word=id2word, chunksize=2000, eta='auto', iterations=400, num_topics=n, passes=20, eval_every=None,random_state=42)\n",
    "#     lda_coherence = CoherenceModel(model=lda_model_c, texts=data_ready,dictionary=id2word, coherence='c_v')\n",
    "#     lda_para_model_n.append((n, lda_model_c, lda_coherence.get_coherence()))\n",
    "# pd.DataFrame(lda_para_model_n, columns=[\"n\", \"model\",\"coherence\"]).set_index(\"n\")[[\"coherence\"]].plot(figsize=(16,9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42815624",
   "metadata": {},
   "source": [
    "### 2.3 Create a table so we can see which topic is assigned to each document\n",
    "\n",
    "The following table shows the assigned topic to every single document. Only the first 10 rows are shown for brevity. To see the whole table delete \"head(10)\" from the very bottom of the follow code chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5181211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40096896",
   "metadata": {},
   "source": [
    "### 2.4 Table that shows the words that contribute the most to each topic, with the review that contributes the most to that topic\n",
    "\n",
    "The following table shows for each topic (\"Topic_Num\") the most important words for that topic (\"Keywords\") and a sample review that contributes the most to that topic (Review = \"Representative Text\", review contribution = \"Topic_Perc_Contribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745edc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63565ee",
   "metadata": {},
   "source": [
    "## 3. Visualtion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43d6327",
   "metadata": {},
   "source": [
    "### 3.1 Wordclouds\n",
    "\n",
    "This chunk produces word clouds for each topic, showing more important words for each topic with a bigger size. These images are saved to your directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2070231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Wordcloud of Top N words in each topic\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=stop_words,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "\n",
    "for t in range(lda_model.num_topics):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(WordCloud(background_color=\"white\", max_words=100, width=960,height=540).fit_words(dict(lda_model.show_topic(t, 200))))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Topic #\" + str(t))\n",
    "    plt.show()\n",
    "    plt.savefig(f'topic_{t}.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8137b76c",
   "metadata": {},
   "source": [
    "### 3.2 t-SNE plot\n",
    "\n",
    "This shows the topics in 2 dimensions so we can see the similarity between topics. Over your mouse over each point to see some example reviews for that point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12450193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic weights and dominant topics ------------\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# Get topic weights\n",
    "topic_weights = []\n",
    "for i, row_list in enumerate(lda_model[corpus]):\n",
    "    topic_weights.append([w for i, w in row_list[0]])\n",
    "\n",
    "# Array of topic weights    \n",
    "arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "#arr = arr[np.amax(arr, axis=1) > 0.35]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "tsne_lda = tsne_model.fit_transform(arr)\n",
    "\n",
    "# # Plot the Topic Clusters using Bokeh\n",
    "# output_notebook()\n",
    "# n_topics = 7\n",
    "# mycolors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "# plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(n_topics), \n",
    "#               plot_width=900, plot_height=700)\n",
    "# plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "# show(plot)\n",
    "\n",
    "\n",
    "\n",
    "df['topic'] = topic_num\n",
    "df['topic']\n",
    "\n",
    "from bokeh.plotting import figure, show, output_notebook, save#, output_file\n",
    "from bokeh.models import HoverTool, value, LabelSet, Legend, ColumnDataSource\n",
    "output_notebook()\n",
    "top_labels = {0: 'Topic 0', 1:'Topic 1', 2:'Topic 2', 3:'Topic 3', 4: 'Topic 4', 5: 'Topic 5', 6: 'Topic 6'}\n",
    "cluster_colors = {0: 'blue', 1: 'green', 2: 'yellow', 3: 'red', 4: 'skyblue', 5:'salmon', 6:'orange'}\n",
    "\n",
    "df['colors'] = df['topic'].apply(lambda l: cluster_colors[l])\n",
    "source = ColumnDataSource(dict(\n",
    "    x=tsne_lda[:,0],\n",
    "    y=tsne_lda[:,1],\n",
    "    color=df['colors'],\n",
    "    label=df['topic'].apply(lambda l: top_labels[l]),\n",
    "#     msize= p_df['marker_size'],\n",
    "    topic_key= topic_num,\n",
    "    #title= p_df[u'Title'],\n",
    "    content = df['feedback_message']\n",
    "))\n",
    "\n",
    "\n",
    "title = 'T-SNE visualization of topics'\n",
    "\n",
    "plot_lda = figure(plot_width=1000, plot_height=600, title=title, tools=\"pan,wheel_zoom,box_zoom,reset,hover\", x_axis_type=None, y_axis_type=None, min_border=1)\n",
    "\n",
    "plot_lda.scatter(x='x', y='y', legend='label', source=source,\n",
    "                 color='color', alpha=0.8, size=10)#'msize', )\n",
    "\n",
    "# hover tools\n",
    "hover = plot_lda.select(dict(type=HoverTool))\n",
    "hover.tooltips = {\"content\": \"@content - Topic: @topic_key \"}\n",
    "plot_lda.legend.location = \"top_left\"\n",
    "\n",
    "show(plot_lda)\n",
    "\n",
    "#save the plot\n",
    "# save(plot_lda, '{}.html'.format(title))\n",
    "\n",
    "\n",
    "# import seaborn as sb\n",
    "# output_notebook()\n",
    "# #plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "# plt.figure(figsize=(16, 9))\n",
    "# sb.scatterplot(\n",
    "#     tsne_lda[:,0], y=tsne_lda[:,1], hue=topic_num, \n",
    "#     legend=\"full\", palette=\"rainbow\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6bb546",
   "metadata": {},
   "source": [
    "### 3.3 pyLDAvis plot\n",
    "\n",
    "This plot again shows the topics plotted in 2 dimensions. The distance between the topics is a measure of their similarity. If the topics are further away, the topics are less similar. Hover your mouse over each topic to see what the most important words are in that topic. You can also use the \"Next Topic\" button to look at each topic, since some topics are close together and it's difficult to pin point them with the mouse. \n",
    "\n",
    "**Important** to note here that the topic numbers do not correspond with the topic numbers in the rest of the report. This is a weakness of pyLDAvis. You can decode the topics as the following:\n",
    "\n",
    "pyLDAvis Topic = Original topic number (from above) <br>\n",
    "Topic 1 = Topic 3 <br>\n",
    "Topic 2 = Topic 0 <br>\n",
    "Topic 3 = Topic 2 <br>\n",
    "Topic 4 = Topic 1 <br>\n",
    "Topic 5 = Topic 4 <br>\n",
    "Topic 6 = Topic 5 <br>\n",
    "Topic 7 = Topic 6 <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9889ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary=id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a97eddb",
   "metadata": {},
   "source": [
    "### 3.4 Plot of changing topic proportions over time.\n",
    "\n",
    "This plots shows how the volume of each topic changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = df.groupby(['year','topic'], as_index=True).count()\n",
    "df_ts1 = df_ts[['Date']]\n",
    "df_ts2 = df_ts1.groupby(level=0).apply(lambda x: 100 * x / float(x.sum()))\n",
    "df_ts3 = df_ts2.pivot_table(index=[\"year\"], \n",
    "                    columns='topic', \n",
    "                    values='Date')\n",
    "df_ts3.index= pd.to_datetime(df_ts3.index,format='%Y')\n",
    "df_ts3.plot.area(figsize=(10,7), use_index=True,x_compat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c688ce3",
   "metadata": {},
   "source": [
    "## 4. Classifying new reviews into the topics.\n",
    "\n",
    "This next section uses the model we created and inputs new reviews and then gives these reviews one of the 7 topics that we created. I used two mock reviews that I created to show which topic they are assigned to. \n",
    "\n",
    "You can import new data, call it new_df and have the reviews take the column name \"feedback_message\" and substitute this importing of data into the following chunk. The next chunk (aka cell) created fake data. It can be substituted with real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e91e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATION OF FAKE DATA HERE\n",
    "new_df=pd.DataFrame({'feedback_message':[\n",
    "    'scooter, in, on, open, no, time, stop, get, back, need', # review 1\n",
    "    'bike use box please middle top road' #review 2\n",
    "]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cad87b",
   "metadata": {},
   "source": [
    "### 4.1 The following table assigns  each new review to a topic\n",
    "\n",
    "The table shows that the first mock review is assigned to the topic 0, looking at the \"Dominant_Topic\" column. The second review is assigned to topic 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aaa6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data = new_df.feedback_message.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:3])\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=10) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=5)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "# !python3 -m spacy download en  # run in terminal once\n",
    "data_ready = process_words(data_words)  # processed Text Data!\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
